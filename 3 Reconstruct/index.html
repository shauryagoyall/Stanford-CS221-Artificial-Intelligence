<head>
  <title>Text Reconstruction</title>
  <script src="plugins/main.js"></script>
  <script src="grader-all.js"></script>

  <style type="text/css">
    .nl { font-family:monospace; }
  </style>
</head>

<body onload="onLoad('reconstruct', '<a href=mailto:arvind98@stanford.edu>Arvind Sridhar<a>', '10/04/2021', 'https://edstem.org/us/courses/13379/discussion/679061')">

<div id="assignmentHeader"></div>

<p><img src="holykeys.png" alt=""/></p>

<p>
  In this homework, we consider two
  tasks: <i>word segmentation</i> and <i>vowel insertion</i>.

  Word segmentation often comes up when processing many non-English
  languages, in which words might not be flanked by spaces on either
  end, such as written Chinese or long compound German
  words.<sup><a href="#fn-1">[1]</a></sup>

  Vowel insertion is relevant for languages like Arabic or Hebrew,
  where modern script eschews notations for vowel sounds
  and the human reader infers them from
  context.<sup><a href="#fn-2">[2]</a></sup> More generally, this is an
  instance of a reconstruction problem with a lossy encoding and some
  context.
</p>
<p>
  We already know how to optimally solve any particular
  search problem with graph search algorithms such as
  uniform cost search or A*.  Our goal here is modeling &mdash; that is,
  converting real-world tasks into state-space search problems.
</p>

<p>
  We've created a LaTeX template <a href="../../with-prompt-templates/reconstruct-template.zip">here</a> for you to use that contains the prompts for each question.
</p>

<!------------------------------------------------------------>
<div class="problemTitle">Setup: $n$-gram language models and
uniform-cost search</div>

<p>
  Our algorithm will base its segmentation and insertion decisions
  on the cost of processed text according to a <i>language model</i>.
  A language model is some function of the processed text that
  captures its fluency.
</p>

<p>
  A very common language model in NLP is an $n$-gram sequence model. This is a
  function that, given $n$ consecutive words, provides a cost based on
  the negative log likelihood that the $n$-th word appears just after the first
  $n-1$ words.<sup><a href="#fn-3">[3]</a></sup>

  The cost will always be positive, and lower costs indicate better
  fluency.<sup><a href="#fn-4">[4]</a></sup>
  As a simple example: In a case where $n=2$ and $c$ is our
  $n$-gram cost function, $c($<span class="nl">big</span>, <span class="nl">fish</span>$)$
  would be low, but $c($<span class="nl">fish</span>, <span class="nl">fish</span>$)$
  would be fairly high.
</p>
<p>
  Furthermore, these costs are additive: For a unigram model $u$ ($n = 1$),
  the cost assigned to $[w_1, w_2, w_3, w_4]$ is
 \[
   u(w_1) + u(w_2) + u(w_3) + u(w_4).
  \]

  Similarly, for a bigram model $b$ ($n = 2$), the cost is
   \[
    b(w_0, w_1) +
    b(w_1, w_2) +
    b(w_2, w_3) +
    b(w_3, w_4),
  \]
  where $w_0$ is <code>-BEGIN-</code>, a special token that denotes the beginning of the sentence.
</p>

<p>
  <b>Note:</b> We have estimated $u$ and $b$ based on the statistics of $n$-grams in text (leo-will.txt).
  Note that any words not in the corpus (like "hello") are automatically assigned a high cost.
  This might lead to some unexpected sentences but you do not have to worry about that.
</p>

<p>
  A note on low-level efficiency and expectations: This assignment was
  designed considering input sequences of length no greater than
  roughly 200, where these sequences can be sequences of characters or of
  list items, depending on the task.  Of course, it's great if programs
  can tractably manage larger inputs, but it's okay if such inputs
  can lead to inefficiency due to overwhelming state space growth.
</p>

<p>
	You are encouraged to look over the given codebase and how functions like cleanLine()
	(in wordsegUtil.py) are called by grader.py and shell.py to preprocess lines.
</p>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 1: Word Segmentation</div>

<p>
  In word segmentation, you are given as input a string of
  alphabetical characters (<code>[a-z]</code>) without whitespace, and
  your goal is to insert spaces into this string such that the result
  is the most fluent according to the language model.
</p>

<ol class="problem">

<li class="writeup" id="1a">
  <p>
    Suppose that we have a unigram model $u$ and we are given the string <span class="nl">breakfastservedinside</span>. 
    The unigram costs of words are given as $u($<span class="nl">break</span>$)=3$, $u($<span class="nl">fast</span>$)=6$, 
    $u($<span class="nl">breakfast</span>$)=8$, $u($<span class="nl">served</span>$)=8$,
    $u($<span class="nl">in</span>$)=3$, $u($<span class="nl">side</span>$)=5$,<br>
    $u($<span class="nl">inside</span>$)=2$. Assume $u(s)=100$ for any other substring $s$ of our string. 
  </p>

  <p>Consider the following greedy algorithm:
  Begin at the front of the string.  Find the
  ending position for the next word that minimizes the
  language model cost.
  Repeat, beginning at the end of this chosen segment.
  
  <p>
    What is the total model cost from running this greedy algorithm on <span class="nl">breakfastservedinside</span>? 
    Is this greedy search optimal for general inputs? In other words, does it find the lowest-cost segmentation of any input?
    Explain why or why not in 1-2 sentences.
  </p>

  <div class="expected"> The value of the total model cost and an explanation of why the greedy algorithm is or is not optimal.</div>

</li>

<li class="code" id="1b">
  <p>
    Implement an algorithm that finds
    the optimal word segmentation of an input character sequence.
    Your algorithm will consider costs based simply on a unigram cost function.
	<code>UniformCostSearch</code> (UCS) is implemented for you in 
	<code>util.py</code>, and you should make use of it here.
	<sup><a href="#fn-5">[5]</a></sup>
  </p>
  <p>
    Before jumping into code, you should think about how to frame
    this problem as a state-space <b>search problem</b>.  How would you
    represent a state?  What are the successors of a state?  What are
    the state transition costs?  (You don't need to answer these
    questions in your writeup.)
  </p>
  <p>
    Fill in the member functions of
    the <code>SegmentationProblem</code> class and
    the <code>segmentWords</code> function.

    The argument <code>unigramCost</code> is a function that takes in
    a single string representing a word and outputs its unigram cost.
    You can assume that all of the inputs would be in lower case.

    The function <code>segmentWords</code> should return the segmented
    sentence with spaces as delimiters, i.e. <code>' '.join(words)</code>.

  </p>
  <p>
    For convenience, you can actually run <code>python
    submission.py</code> to enter a console in which you can type
    character sequences that will be segmented by your implementation
    of <code>segmentWords</code>.  To request a segmentation,
    type <code>seg mystring</code> into the prompt.  For example:
    <pre>
      >> seg thisisnotmybeautifulhouse

        Query (seg): thisisnotmybeautifulhouse

        this is not my beautiful house
    </pre>
    Console commands other than <code>seg</code> &mdash;
    namely <code>ins</code> and <code>both</code> &mdash; will be used in
    the upcoming parts of the assignment.  Other commands that might
    help with debugging can be found by typing <code>help</code> at
  the prompt.
  <p>
    <b>Hint</b>: You are encouraged to refer to <code>NumberLineSearchProblem</code> and <code>GridSearchProblem</code>
    implemented in <code>util.py</code> for reference. They don't contribute to testing your
    submitted code but only serve as a guideline for what your code should look like.
  </p>
  <p>
    <b>Hint</b>: The actions that are valid for the <code>ucs</code> object
    can be accessed through <code>ucs.actions</code>.
  </p>

  <div class="expected"> An implementation of the member functions of
    the <code>SegmentationProblem</code> class and
    the <code>segmentWords</code> function. </div>
</li>

</ol>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 2: Vowel Insertion</div>

<p>
  Now you are given a sequence of English words with their vowels
  missing (A, E, I, O, and U; never Y).  Your task is to place vowels
  back into these words in a way that maximizes sentence fluency
  (i.e., that minimizes sentence cost).  For this task, you will use a
  bigram cost function.
</p>
<p>
  You are also given a mapping <code>possibleFills</code> that maps
  any vowel-free word to a set of possible reconstructions (complete
  words).<sup><a href="#fn-6">[6]</a></sup> For
  example, <code>possibleFills('fg')</code>
  returns <code>set(['fugue', 'fog'])</code>.
</p>

<ol class="problem">

<li class="writeup" id="2a">
  <p>
   Consider the following greedy-algorithm: from left to right, repeatedly pick
   the immediate-best vowel insertion for the current vowel-free word, given
   the insertion that was chosen for the previous vowel-free word.
   This algorithm does <i>not</i> take into account future insertions beyond the current word.
  </p>
  <p>
  Show that this greedy algorithm is suboptimal, by providing
  a realistic counter-example using English text. Make any assumptions you'd like
  about <code>possibleFills</code> and the bigram cost function, but bigram costs
  must be positive.
  </p>
  <p>
    In creating this example, lower cost should
    indicate better fluency. Note that the cost function doesn't need to
    be explicitly defined. You can just point out the relative cost of
    different word sequences that are relevant to the example you provide.
    And your example should be based on a realistic
    English word sequence &mdash; don't simply use abstract symbols with
    designated costs. Limit your answers to 4 sentences max to receive full
    credits.
  </p>
  <div class="expected"> A specific (realistic) example explained within a couple of sentences.</div>
</li>

<li class="code" id="2b">
  <p>
     Implement an algorithm that finds optimal vowel insertions.  Use
    the UCS subroutines.
  </p>
  <p>
    When you've completed your implementation, the
    function <code>insertVowels</code> should return the reconstructed
    word sequence as a string with space delimiters, i.e.
    <code>' '.join(filledWords)</code>. Assume that you have a list of strings as
    the input, i.e. the sentence has already been split into words for you. Note
    that the empty string is a valid element of the list.
  </p>
  <p>
    The argument <code>queryWords</code> is the input sequence of
    vowel-free words.  Note that the empty string is a valid such
    word.  The argument <code>bigramCost</code> is a function that
    takes two strings representing two sequential words and provides
    their bigram score.  The special out-of-vocabulary
    beginning-of-sentence word <code>-BEGIN-</code> is given
    by <code>wordsegUtil.SENTENCE_BEGIN</code>.  The
    argument <code>possibleFills</code> is a function that takes a word
    as a string and returns a <code>set</code> of
    reconstructions.
  </p>
  <p>
    Since we use a limited corpus, some seemingly obvious
    strings may have no filling, such as <code>chclt -> {}</code>,
    where <code>chocolate</code> is actually a valid filling.
    Don't worry about these cases.
  </p>
  <p>
    <b>Note:</b> Only for Problem 2, if some vowel-free word $w$
    has no reconstructions according to <code>possibleFills</code>,
    your implementation should consider $w$ itself as the sole
    possible reconstruction. Otherwise you should always use one
    of its possible completions according to <code>possibleFills</code>.
    This is NOT the case for Problem 3.
  </p>
  <p>
    Use the <code>ins</code> command in the program console to try
    your implementation.  For example:
    <pre>
      >> ins thts m n th crnr

        Query (ins): thts m n th crnr

        thats me in the corner
    </pre>
    The console strips away any vowels you do insert, so you can
    actually type in plain English and the vowel-free query will be
    issued to your program.  This also means that you can use a single
    vowel letter as a means to place an empty string in the sequence.
    For example:
    <pre>
      >> ins its a beautiful day in the neighborhood

        Query (ins): ts  btfl dy n th nghbrhd

        its a beautiful day in the neighborhood
    </pre>

    <div class="expected"> An implementation of the member functions of
    the <code>VowelInsertionProblem</code> class and
    the <code>insertVowels</code> function. </div>
</li>

</ol>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 3: Putting it Together</div>

<p>
  We'll now see that it's possible to solve both of these tasks at
  once.  This time, you are given a whitespace-free and vowel-free string
  of alphabetical characters.  Your goal is to insert spaces and
  vowels into this string such that the result is as fluent as possible.
  As in the previous task, costs are based on a bigram cost function.
</p>

<ol class="problem">

<li class="writeup" id="3a">
  <p> Consider a search problem for finding the optimal space and
  vowel insertions. Formalize the problem as a search problem: What
  are the states, actions, costs, initial state, and end test? Try to find a
  minimal representation of the states.
  </p>

    <div class="expected"> A formal definition of the search problem with 
    definitions for the states, actions, costs, initial state, and end test.</div>

</li>

<li class="code" id="3b">
  <p>
     Implement an algorithm that finds the optimal space and
    vowel insertions.  Use the UCS subroutines.
  </p>
  <p>
    When you've completed your implementation, the
    function <code>segmentAndInsert</code> should return a segmented
    and reconstructed word sequence as a string with space delimiters,
    i.e. <code>' '.join(filledWords)</code>.
  </p>
  <p>
    The argument <code>query</code> is the input string of space- and
    vowel-free words.  The argument <code>bigramCost</code> is a
    function that takes two strings representing two sequential words
    and provides their bigram score.  The special out-of-vocabulary
    beginning-of-sentence word <code>-BEGIN-</code> is given
    by <code>wordsegUtil.SENTENCE_BEGIN</code>.  The
    argument <code>possibleFills</code> is a function that takes a word
    as a string and returns a <code>set</code> of reconstructions.
  </p>
  <p>
    <b>Note:</b> In problem 2, a vowel-free word could, under certain
    circumstances, be considered a valid reconstruction of itself.
    <i>However</i>, for this problem, in your output, you should only include
    words that are the reconstruction of some vowel-free word according to
    <code>possibleFills</code>.  Additionally, you should not include words
    containing only vowels such as <code>a</code> or <code>i</code> or out of
    vocabulary words; all words should include at least one consonant from the 
    input string and a solution is guaranteed. Additionally, aim to use
    a minimal state representation for full credit.
  </p>
  <p>
    Use the command <code>both</code> in the program console to try
    your implementation.  For example:
    <pre>
      >> both mgnllthppl

        Query (both): mgnllthppl

        imagine all the people
    </pre>
  <div class="expected"> An implementation of the member functions of
    the <code>JointSegmentationInsertionProblem</code> class and
    the <code>segmentAndInsert</code> function. 
  </div>
</li>
</ol>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 4: Failure Modes and Transparency</div>

<p>
  Now that you have a working reconstruction algorithm, let’s try reconstructing a few examples. Take each of the below phrases and pass them to the <code>both</code> command from the program console.

  <li>
    Example 1: “yrhnrshwllgrcslyccptthffr” (original: “your honor she will graciously accept the affair”)
  </li><li>
    Example 2: “wlcmtthhttkzn” (original: “welcome to the hot take zone”)
  </li><li>
    Example 3: “grlwllnrflprrghtnw” (original: “girl we all in our flop era right now”)
  </li>
</p>

<ol class="problem">

<li class="writeup" id="4a">
  <p>
    First, indicate which examples were reconstructed correctly versus incorrectly.
    Recall that the system chooses outputs based on a bigram cost function
    <sup><a href="#fn-4">[4]</a></sup>,
    which is roughly low if a bigram occurred in
    Leo Tolstoy's <i>War and Peace</i> and William Shakespeare's <i>Romeo and Juliet</i>,
    and high if it didn't (the details don't matter for this problem).
    Then, explain what about the training data may have led to this behavior.
  </p>
  <div class="expected">1-2 sentences listing whether each example was correctly or incorrectly reconstructed  and a brief explanation <u>with justification</u> as to what about the training data may have led to this result.</div>
</li>

<li class="writeup" id="4b">
  <p>
    Your system, like all systems, has limitations and potential points of failure. As a responsible AI practitioner, it’s important for you to recognize and communicate these limitations to users of the systems you build. Imagine that you are deploying your search algorithm from this assignment to real users on mobile phones.
    Write a <b>transparency statement</b> for your system,
    which communicates to users the conditions under which the system should be
    expected to work and when it might not work.
  </p>
  <div class="expected">2-4 sentences explaining the potential failure modes of
    your system.  Be sure to acknowledge the limitations that your system has
    and who should know about these limitations (i.e., who are the affected
    parties?).</div>
</li>

<li class="writeup" id="4c">
  <p>
    Given the limitations found in part (a) and described in your transparency statement from (b), how could you improve your system?
  </p>
  <div class="expected">2-4 sentences proposing a change to the cost function, how you would implement it,
    and why it would address the limitations you identified above.</div>
</li>

</ol>

<!------------------------------------------------------------>
<!-- <div class="problemTitle">Problem 5: A* Karel!</div>

<p>
  We'll now see a basic application of A* search in the context of everyone's favorite
  robot, Karel! In our context, Karel has a cookie craving and is trying to reach the
  cell with the cookie in the fewest number of time steps. Karel is hungry and aims to use 
  A* search to optimize the cookie search and needs your help. 
  Note that Karel can only use the following commands: turnLeft(), turnRight(), moveForward().
  Karel can finish one command in 1 time step in white cells, but needs 10 time steps to finish 
  one command in the swamp (dark green cells).
</p>

<p><img src="astar_search.png" alt=""/></p>

<ol class="problem">

<li class="writeup" id="5a">
  <p> 
    The bottom left cell in the grid shown above is $(0, 0)$ in the Cartesian plane. Karel is currently at
    cell $(1, 0)$, is facing East, and wants to reach the cell containing the cookie (facing any direction).
    We can define $T^{*}(a, b, d)$ to be the minimum number of time steps Karel needs to reach the cookie starting
    from cell $(a, b)$ and initially facing direction d. Assume for this part that Karel has an admissible
    heuristic $h(a, b, d)$. What can we say about how $h(1, 0, East)$ compares to $T^{*}(1, 0, East)$?
  </p>
  <div class="expected"> A mathematical expression relating $h(1, 0, East)$ to $T^{*}(1, 0, East)$ along with a brief justification.</div>
</li>

<li class="writeup" id="5b">
  <p> 
    How would we define an admissible heuristic $h(a, b, d)$ for Karel as described in part a? In particular, how
    could we relax Karel's search problem to define a different cost metric, which is always
    optimistic when used as a heuristic in the original (non-relaxed) setting? Explain why the cost metric you define
    is always optimistic. Note that Karel always knows the final (cell) position of the cookie.
  </p>
  <p>
    Here "optimistic" describes the property of a heuristic, and oftentimes, we choose our heuristic for a search
    problem to be the cost metric for a relaxed version of the search problem. For this question, we want you
    to come up with a relaxed version of Karel's search problem, and define its cost metric, which is used as
    the heuristic for the original problem. You need to explain why this heuristic is always optimistic.
  </p>
  <div class="expected"> A description of a relaxed search problem and a definition of a different cost metric with
  a justification for why it is always optimistic. The cost metric should be concrete (i.e., explain exactly how the
  cost is computed in the relaxed setting).</div>
</li>

</ol> -->
<!-- <li class="writeup" id="3c">
  <p>
    Let's find a way to speed up the joint insertion of space and vowel with A*.
    First start with a <b>relaxed search problem</b> $P_{rel}$ where 
    $Cost_{rel}(s, a) \leq Cost(s, a)$ and solve for an exact $FutureCost_{rel}(s)$ function.
    Because all costs in our relaxed problem are no larger than the corresponding costs
    in the original problem, we can conclude that $FutureCost_{rel}(s) \leq FutureCost(s)$.
    Recall that for A* we will need a heuristic function $h(s)$, which is attempting
    to measure how costly it is to reach a goal state when starting from $s$, satisfying
    $h(s) \leq FutureCost(s)$, thus we can define the heuristic function
    $h(s) = FutureCost_{rel}(s)$.
    <br><br>

    Given a bigram model $b$, a function that takes any $(w',w)$ and returns a number,
    your task is to define a unigram model $f_b$, another function that takes 
    any $w$ and returns a number, <i>based on $b$</i>. <br><br>

    Use this function $f_b$ to help define $P_{rel}$.

    <p>One example of a $f_b$ is $f_b(w) = b(w, w)$. However, this will not lead to
      a <i>consistent</i> heuristic because $b(w, w)$ is not guaranteed to
      be less than or equal to $b(w', w)$ with this scheme. For example, $b(\text{"dog"}, \text{"dog"})$
      would have higher cost than $b(\text{"the"}, \text{"dog"})$ as the later pair sounds more natural,
      which violates the necessary condition of the relaxed cost being lower than the original cost
      in a relaxed problem.
    </p>

    <p> Explicitly define the states, actions, cost, start state, and end state of the <b>relaxed problem</b>
      and explain why $h(s)$ is consistent.</p>

  <p>
      <i>Hint:</i> If $f_b$ only accepts a single w, do we need to keep track of the previous word in our state?
  </p>

</li> -->
<!-- <li class="writeup" id="3d">
  <p>
  We defined many different search techniques in class, so let's see how they relate to one another.
  </p>
  Is UCS a special case of A*? Explain why or why not. <br><br>
  Is BFS a special case of UCS? Explain why or why not.
  <p>Your explanations can be short. 1 or 2 sentences will suffice.</p>
</li> -->

<hr/>
<p id="fn-1"> [1]
  In German, <i>Windschutzscheibenwischer</i> is "windshield wiper".
  Broken into parts: <i>wind</i> ~ wind; <i>schutz</i> ~ block /
  protection; <i>scheiben</i> ~ panes; <i>wischer</i> ~ wiper.
</p>
<p id="fn-2"> [2]
  See <a href="https://en.wikipedia.org/wiki/Abjad">https://en.wikipedia.org/wiki/Abjad</a>.
</p>
<p id="fn-3"> [3]
  This model works under the assumption that text roughly satisfies
  the <a href="https://en.wikipedia.org/wiki/Markov_property">Markov
  property</a>.
</p>
<p id="fn-4"> [4]
  Modulo edge cases, the $n$-gram model score in this assignment is
  given by $\ell(w_1, \ldots, w_n) = -\log p(w_n \mid w_1, \ldots,
  w_{n-1})$.  Here, $p(\cdot)$ is an estimate of the conditional
  probability distribution over words given the sequence of previous
  $n-1$ words.  This estimate is based on word frequencies
  in Leo Tolstoy's <i>War and Peace</i> and William
  Shakespeare's <i>Romeo and Juliet</i>.
</p>
<p id="fn-5"> [5]
  Solutions that use UCS ought to exhibit fairly fast execution time
  for this problem, so using A* here is unnecessary.
</p>
<p id="fn-6"> [6]
  This mapping was also obtained by reading Tolstoy and Shakespeare
  and removing vowels.
</p>

<div id="feedback" data-survey-url="https://forms.gle/JzuYMk7sSRUEXDss7"></div>

</body>
